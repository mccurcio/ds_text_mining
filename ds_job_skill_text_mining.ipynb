{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining for common words\n",
    "\n",
    "I produced a .txt file that has the job skill keywords for 73 jobs listed via Linkedin. \n",
    "The file has 730 lines, where each line is a skill phrase.\n",
    "\n",
    "For example, skills are listed as:\n",
    "\n",
    "```\n",
    "Cloud Computing\n",
    "Learning\n",
    "Microsoft Azure\n",
    "Mobile Application Development\n",
    "```\n",
    "\n",
    "**To Do**   \n",
    "- It would be interesting to find the most and least common words.   \n",
    "- It would also be good to find the most and least common skill phrases.   \n",
    "\n",
    "### The 20 most common words are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 20 most common words are:\n",
      "data 165\n",
      "science 58\n",
      "analytics 56\n",
      "analysis 45\n",
      "language 40\n",
      "programming 32\n",
      "skills 28\n",
      "sql 26\n",
      "analytical 25\n",
      "learning 23\n",
      "python 23\n",
      "communication 23\n",
      "computer 21\n",
      "business 21\n",
      "visualization 21\n",
      "management 19\n",
      "microsoft 17\n",
      "machine 16\n",
      "modeling 16\n",
      "databases 15\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mccurcio/ds_text_mining/main/73_ds_job_skills.txt\"\n",
    "\n",
    "# Download the file contents\n",
    "response = urllib.request.urlopen(url)\n",
    "data = response.read().decode(\"utf-8\")\n",
    "\n",
    "# Tokenize the text into words and count the occurrences of each word\n",
    "words = re.findall(r'\\b\\w+\\b', data.lower())\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# Get the 20 most common words\n",
    "most_common = word_counts.most_common(20)\n",
    "\n",
    "# Print the results\n",
    "print(\"The 20 most common words are:\")\n",
    "for word, count in most_common:\n",
    "    print(word, count)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 20 least common words are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 20 least common words are:\n",
      "time 1\n",
      "principles 1\n",
      "accounting 1\n",
      "statutory 1\n",
      "products 1\n",
      "improvement 1\n",
      "collection 1\n",
      "programs 1\n",
      "training 1\n",
      "rpa 1\n",
      "automation 1\n",
      "robotic 1\n",
      "application 1\n",
      "mobile 1\n",
      "cloud 1\n",
      "models 1\n",
      "ssrs 1\n",
      "oracle 1\n",
      "mis 1\n",
      "actuarial 1\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mccurcio/ds_text_mining/main/73_ds_job_skills.txt\"\n",
    "\n",
    "# Download the file contents\n",
    "response = urllib.request.urlopen(url)\n",
    "data = response.read().decode(\"utf-8\")\n",
    "\n",
    "# Tokenize the text into words and count the occurrences of each word\n",
    "words = re.findall(r'\\b\\w+\\b', data.lower())\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# Get the 20 least common words\n",
    "least_common = word_counts.most_common()[:-21:-1]\n",
    "\n",
    "# Print the results\n",
    "print(\"The 20 least common words are:\")\n",
    "for word, count in least_common:\n",
    "    print(word, count)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 20 most common phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Data Science\": 37\n",
      "\"Data Analytics\": 26\n",
      "\"Data Analysis\": 24\n",
      "\"Analytical Skills\": 23\n",
      "\"SQL\": 22\n",
      "\"Python (Programming Language)\": 22\n",
      "\"Computer Science\": 19\n",
      "\"Communication\": 19\n",
      "\"Analytics\": 16\n",
      "\"Machine Learning\": 15\n",
      "\"Data Visualization\": 14\n",
      "\"Statistics\": 13\n",
      "\"Natural Language Processing (NLP)\": 10\n",
      "\"Databases\": 10\n",
      "\"Data Modeling\": 9\n",
      "\"Business Intelligence (BI)\": 7\n",
      "\"Data Mining\": 6\n",
      "\"Data Cleaning\": 6\n",
      "\"Dashboard\": 6\n",
      "\"Deep Learning\": 6\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "\n",
    "# Fetch data from the URL\n",
    "url = \"https://raw.githubusercontent.com/mccurcio/ds_text_mining/main/73_ds_job_skills.txt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Extract the text and split into lines\n",
    "text = response.text.strip()\n",
    "lines = text.split(\"\\n\")\n",
    "\n",
    "# Quote each line\n",
    "quoted_lines = [f'\"{line}\"' for line in lines]\n",
    "\n",
    "# Count the occurrences of each quoted phrase\n",
    "phrase_counts = Counter(quoted_lines)\n",
    "\n",
    "# Print the 20 most common phrases\n",
    "for phrase, count in phrase_counts.most_common(20):\n",
    "    print(f\"{phrase}: {count}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 20 least common phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 20 least common phrases in the file are:\n",
      "\n",
      "\"Actuarial Science\": 1\n",
      "\"Management Information Systems (MIS)\": 1\n",
      "\"Database Administration\": 1\n",
      "\"Oracle Database\": 1\n",
      "\"Query Writing\": 1\n",
      "\"Reporting Requirements\": 1\n",
      "\"SQL Server Reporting Services (SSRS) \": 1\n",
      "\"Data Models\": 1\n",
      "\"Cloud Computing\": 1\n",
      "\"Learning\": 1\n",
      "\"Mobile Application Development\": 1\n",
      "\"Robotic Process Automation (RPA)\": 1\n",
      "\"Training Programs \": 1\n",
      "\"Data Collection\": 1\n",
      "\"Process Improvement\": 1\n",
      "\"Quality Management\": 1\n",
      "\"SAP Products\": 1\n",
      "\"Statutory Accounting Principles (SAP) \": 1\n",
      "\"Microsoft Power Query\": 1\n",
      "\"Time Management\": 1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "\n",
    "# Fetch data from the URL\n",
    "url = \"https://raw.githubusercontent.com/mccurcio/ds_text_mining/main/73_ds_job_skills.txt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Extract the text and split into lines\n",
    "text = response.text.strip()\n",
    "lines = text.split(\"\\n\")\n",
    "\n",
    "# Quote each line\n",
    "quoted_lines = [f'\"{line}\"' for line in lines]\n",
    "\n",
    "# Count the occurrences of each quoted phrase\n",
    "least_common_phrases = phrase_counts.most_common()[-20:]\n",
    "\n",
    "# Print the least common phrases\n",
    "print(\"The 20 least common phrases in the file are:\\n\")\n",
    "for phrase, count in least_common_phrases:\n",
    "    print(f\"{phrase}: {count}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 350 unique words in the file.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Fetch data from the URL\n",
    "url = \"https://raw.githubusercontent.com/mccurcio/ds_text_mining/main/73_ds_job_skills.txt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Extract the text and split into words\n",
    "text = response.text.strip()\n",
    "words = text.split()\n",
    "\n",
    "# Count the number of unique words\n",
    "unique_words = set(words)\n",
    "num_unique_words = len(unique_words)\n",
    "\n",
    "# Print the result\n",
    "print(f\"There are {num_unique_words} unique words in the file.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The number of unique phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 296 unique quoted phrases in the file.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Fetch data from the URL\n",
    "url = \"https://raw.githubusercontent.com/mccurcio/ds_text_mining/main/73_ds_job_skills.txt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Extract the text and split into lines\n",
    "text = response.text.strip()\n",
    "lines = text.split(\"\\n\")\n",
    "\n",
    "# Quote each line\n",
    "quoted_lines = [f'\"{line}\"' for line in lines]\n",
    "\n",
    "# Count the number of unique quoted phrases\n",
    "unique_quoted_lines = set(quoted_lines)\n",
    "num_unique_quoted_lines = len(unique_quoted_lines)\n",
    "\n",
    "# Print the result\n",
    "print(f\"There are {num_unique_quoted_lines} unique quoted phrases in the file.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print all the phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the phrases in the file sorted by their counts are:\n",
      "\"Data Science\": 37\n",
      "\"Data Analytics\": 26\n",
      "\"Data Analysis\": 24\n",
      "\"Analytical Skills\": 23\n",
      "\"SQL\": 22\n",
      "\"Python (Programming Language)\": 22\n",
      "\"Computer Science\": 19\n",
      "\"Communication\": 19\n",
      "\"Analytics\": 16\n",
      "\"Machine Learning\": 15\n",
      "\"Data Visualization\": 14\n",
      "\"Statistics\": 13\n",
      "\"Natural Language Processing (NLP)\": 10\n",
      "\"Databases\": 10\n",
      "\"Data Modeling\": 9\n",
      "\"Business Intelligence (BI)\": 7\n",
      "\"Data Mining\": 6\n",
      "\"Data Cleaning\": 6\n",
      "\"Dashboard\": 6\n",
      "\"Deep Learning\": 6\n",
      "\"Tableau \": 6\n",
      "\"Pattern Recognition\": 5\n",
      "\"Predictive Analytics \": 5\n",
      "\"Predictive Modeling\": 5\n",
      "\"R (Programming Language)\": 5\n",
      "\"Visualization \": 5\n",
      "\"Problem Solving\": 5\n",
      "\"A/B Testing\": 4\n",
      "\"Mathematics\": 4\n",
      "\"Statistical Analysis\": 4\n",
      "\"Business Analysis\": 4\n",
      "\"Database Design\": 4\n",
      "\"Extract, Transform, Load (ETL)\": 4\n",
      "\"Project Management\": 4\n",
      "\"Critical Thinking\": 4\n",
      "\"Microsoft Excel\": 4\n",
      "\"Artificial Intelligence (AI)\": 3\n",
      "\"Amazon Web Services (AWS)\": 3\n",
      "\"Azure Databricks\": 3\n",
      "\"Microsoft Azure\": 3\n",
      "\"Experimental Design\": 3\n",
      "\"SAS (Software)\": 3\n",
      "\"Clinical Data\": 3\n",
      "\"Data Engineering\": 3\n",
      "\"Data Management\": 3\n",
      "\"Predictive Analytics\": 3\n",
      "\"Statistical Analysis \": 3\n",
      "\"Applied Mathematics\": 3\n",
      "\"Data Architecture\": 3\n",
      "\"Statistical Data Analysis\": 3\n",
      "\"Presentations\": 3\n",
      "\"Written Communication \": 3\n",
      "\"Microsoft Office\": 3\n",
      "\"Relational Databases\": 3\n",
      "\"Data Quality\": 3\n",
      "\"Business Requirements\": 3\n",
      "\"Problem Solving \": 3\n",
      "\"Economics\": 3\n",
      "\"Interpersonal Skills\": 2\n",
      "\"Business Strategy\": 2\n",
      "\"Marketing Strategy\": 2\n",
      "\"Reporting & Analysis\": 2\n",
      "\"Scientific Data Management \": 2\n",
      "\"Apache Spark\": 2\n",
      "\"Pandas (Software)\": 2\n",
      "\"DevOps\": 2\n",
      "\"Jira\": 2\n",
      "\"Software Development Life Cycle (SDLC) \": 2\n",
      "\"PySpark\": 2\n",
      "\"Data Wrangling\": 2\n",
      "\"Datasets\": 2\n",
      "\"Attention to Detail\": 2\n",
      "\"Big Data\": 2\n",
      "\"Pattern Recognition \": 2\n",
      "\"Employee Benefits\": 2\n",
      "\"Research\": 2\n",
      "\"Looker (Software)\": 2\n",
      "\"Java\": 2\n",
      "\"Data Warehousing\": 2\n",
      "\"Microsoft Power BI\": 2\n",
      "\"MATLAB\": 2\n",
      "\"R (Programming Language) \": 2\n",
      "\"Web Analytics \": 2\n",
      "\"Microsoft PowerPoint\": 2\n",
      "\"IBM SPSS\": 2\n",
      "\"Business Rules\": 2\n",
      "\"Regulatory Requirements\": 2\n",
      "\"Risk Compliance \": 2\n",
      "\"Architecture\": 2\n",
      "\"Enterprise Architecture\": 2\n",
      "\"Leadership\": 2\n",
      "\"Report Building\": 2\n",
      "\"Software Development\": 2\n",
      "\"Strategy\": 2\n",
      "\"System Architecture\": 2\n",
      "\"TOGAF \": 2\n",
      "\"MicroStrategy\": 2\n",
      "\"Pivot Tables\": 2\n",
      "\"Data Integrity\": 2\n",
      "\"Presentation Skills\": 2\n",
      "\"Visual Basic for Applications (VBA) \": 2\n",
      "\"Visualization\": 2\n",
      "\"Administrative Processes\": 1\n",
      "\"Data Retention\": 1\n",
      "\"Motor Vehicle\": 1\n",
      "\"Program Administration\": 1\n",
      "\"Records Management \": 1\n",
      "\"Operations Research\": 1\n",
      "\"Distributed Computing\": 1\n",
      "\"Model Design\": 1\n",
      "\"Technical Design \": 1\n",
      "\"Python\": 1\n",
      "\"TensorFlow\": 1\n",
      "\"PyTorch\": 1\n",
      "\"Spark\": 1\n",
      "\"GCP\": 1\n",
      "\"Vertex AI\": 1\n",
      "\"DSL\": 1\n",
      "\"Unstructured Data \": 1\n",
      "\"Analytical Solutions\": 1\n",
      "\"Creative Problem Solving\": 1\n",
      "\"Recommender Systems \": 1\n",
      "\"Laptops\": 1\n",
      "\"Statistical Concepts\": 1\n",
      "\"TensorFlow \": 1\n",
      "\"Documentation\": 1\n",
      "\"Possess strong analytical\": 1\n",
      "\"Product Requirements\": 1\n",
      "\"Scope Management\": 1\n",
      "\"Strategic Thinking \": 1\n",
      "\"Bioinformatics\": 1\n",
      "\"Machine Learning Algorithms\": 1\n",
      "\"NGS\": 1\n",
      "\"Research and Development (R&D) \": 1\n",
      "\"Academic Publishing\": 1\n",
      "\"Language Processing\": 1\n",
      "\"Acceptance Testing\": 1\n",
      "\"Clinical Data Management\": 1\n",
      "\"Data Standards\": 1\n",
      "\"Electronic Trial Master File (eTMF)\": 1\n",
      "\"User Acceptance Testing\": 1\n",
      "\"eCRF \": 1\n",
      "\"Ember.js\": 1\n",
      "\"Computer Vision\": 1\n",
      "\"Electrical Engineering\": 1\n",
      "\"Git \": 1\n",
      "\"Oncology\": 1\n",
      "\"Optimization\": 1\n",
      "\"Statistical Programming\": 1\n",
      "\"ggplot\": 1\n",
      "\"Semiconductor Fabrication\": 1\n",
      "\"Semiconductors\": 1\n",
      "\"Version Control \": 1\n",
      "\"Data Structures\": 1\n",
      "\"Programming Languages\": 1\n",
      "\"Statistical Programming \": 1\n",
      "\"Metrics Definition\": 1\n",
      "\"DAX\": 1\n",
      "\"Git\": 1\n",
      "\"ANCOVA\": 1\n",
      "\"ANOVA\": 1\n",
      "\"Dimensionality Reduction\": 1\n",
      "\"Customer Data\": 1\n",
      "\"Biostatistics\": 1\n",
      "\"Clinical Trials\": 1\n",
      "\"Epidemiology\": 1\n",
      "\"SNOMED\": 1\n",
      "\"U.S. Health Insurance Portability and Accountability Act (HI…\": 1\n",
      "\"Unit Testing \": 1\n",
      "\"D3.js\": 1\n",
      "\"Scala \": 1\n",
      "\"Exploratory Data Analysis\": 1\n",
      "\"Hive\": 1\n",
      "\"RStudio\": 1\n",
      "\"Professional Skills \": 1\n",
      "\"Marketing\": 1\n",
      "\"Advertising\": 1\n",
      "\"Online Advertising\": 1\n",
      "\"Interpersonal Relationships\": 1\n",
      "\"Performance Metrics\": 1\n",
      "\"Business Growth\": 1\n",
      "\"C#\": 1\n",
      "\"Coding Experience\": 1\n",
      "\"Mathematical Analysis\": 1\n",
      "\"Microsoft SQL Server\": 1\n",
      "\"Sentiment Analysis \": 1\n",
      "\"Anomaly Detection\": 1\n",
      "\"Calendaring\": 1\n",
      "\"Confidentiality\": 1\n",
      "\"Decision-Making\": 1\n",
      "\"Information Management\": 1\n",
      "\"Office Equipment\": 1\n",
      "\"Graph Databases\": 1\n",
      "\"Recommender Systems\": 1\n",
      "\"Cross-functional Coordination\": 1\n",
      "\"Cross-team Collaboration\": 1\n",
      "\"Data Pipelines\": 1\n",
      "\"Linux \": 1\n",
      "\"Strategic Thinking\": 1\n",
      "\"Cluster Analysis\": 1\n",
      "\"Credit Risk Management\": 1\n",
      "\"Fraud Detection\": 1\n",
      "\"Logistic Regression\": 1\n",
      "\"Random Forest\": 1\n",
      "\"Risk Modeling\": 1\n",
      "\"Underwriting \": 1\n",
      "\"Agile Methodologies\": 1\n",
      "\"IBM Db2\": 1\n",
      "\"MongoDB\": 1\n",
      "\"PostgreSQL \": 1\n",
      "\"Ab Initio\": 1\n",
      "\"Data Preparation\": 1\n",
      "\"Data Profiling\": 1\n",
      "\"Greenplum\": 1\n",
      "\"Relational Databases \": 1\n",
      "\"Quality Control\": 1\n",
      "\"QlikView\": 1\n",
      "\"SQL Server Integration Services (SSIS) \": 1\n",
      "\"Data Manipulation\": 1\n",
      "\"Proactive Monitoring\": 1\n",
      "\"Decision Support\": 1\n",
      "\"Business Analytics\": 1\n",
      "\"Influence Others\": 1\n",
      "\"Requirements Gathering \": 1\n",
      "\"Alteryx\": 1\n",
      "\"Consumer Marketing\": 1\n",
      "\"Cross-functional Team Leadership\": 1\n",
      "\"RACI\": 1\n",
      "\"Requirements Gathering\": 1\n",
      "\"IT Projects\": 1\n",
      "\"Management\": 1\n",
      "\"Project Tracking\": 1\n",
      "\"Quality Assurance\": 1\n",
      "\"Software Development Life Cycle (SDLC)\": 1\n",
      "\"Software Implementation\": 1\n",
      "\"System Testing\": 1\n",
      "\"User Acceptance Testing \": 1\n",
      "\"JavaScript\": 1\n",
      "\"Microsoft SQL Server \": 1\n",
      "\"Statistical Software\": 1\n",
      "\"Finance\": 1\n",
      "\"Financial Analysis\": 1\n",
      "\"Financial Reporting\": 1\n",
      "\"Forecasting\": 1\n",
      "\"Interpersonal Communication\": 1\n",
      "\"Benchmarking\": 1\n",
      "\"Business Insights\": 1\n",
      "\"Marketing Mix Modeling\": 1\n",
      "\"Point of Sale (POS) Systems\": 1\n",
      "\"Sales & Marketing\": 1\n",
      "\"Strategic Leadership \": 1\n",
      "\"Cognitive Science\": 1\n",
      "\"Competitive Assessment\": 1\n",
      "\"Jupyter\": 1\n",
      "\"Personal Accident\": 1\n",
      "\"Pycharm\": 1\n",
      "\"White Papers \": 1\n",
      "\"Adobe Analytics\": 1\n",
      "\"Google Analytics\": 1\n",
      "\"Google BigQuery\": 1\n",
      "\"Google Data Studio\": 1\n",
      "\"Decision Sciences\": 1\n",
      "\"Hypothesis Testing\": 1\n",
      "\"Perl\": 1\n",
      "\"SAP BusinessObjects\": 1\n",
      "\"Stata\": 1\n",
      "\"Text Mining \": 1\n",
      "\"Quantitative Analytics\": 1\n",
      "\"Computerized System Validation (CSV)\": 1\n",
      "\"Data Validation\": 1\n",
      "\"Computer Literacy\": 1\n",
      "\"Conference Presentations\": 1\n",
      "\"Technical Writing\": 1\n",
      "\"Claims Handling\": 1\n",
      "\"Loss Mitigation\": 1\n",
      "\"Partner Relationship Management\": 1\n",
      "\"Actuarial Science\": 1\n",
      "\"Management Information Systems (MIS)\": 1\n",
      "\"Database Administration\": 1\n",
      "\"Oracle Database\": 1\n",
      "\"Query Writing\": 1\n",
      "\"Reporting Requirements\": 1\n",
      "\"SQL Server Reporting Services (SSRS) \": 1\n",
      "\"Data Models\": 1\n",
      "\"Cloud Computing\": 1\n",
      "\"Learning\": 1\n",
      "\"Mobile Application Development\": 1\n",
      "\"Robotic Process Automation (RPA)\": 1\n",
      "\"Training Programs \": 1\n",
      "\"Data Collection\": 1\n",
      "\"Process Improvement\": 1\n",
      "\"Quality Management\": 1\n",
      "\"SAP Products\": 1\n",
      "\"Statutory Accounting Principles (SAP) \": 1\n",
      "\"Microsoft Power Query\": 1\n",
      "\"Time Management\": 1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "\n",
    "# Fetch data from the URL\n",
    "url = \"https://raw.githubusercontent.com/mccurcio/ds_text_mining/main/73_ds_job_skills.txt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Extract the text and split into lines\n",
    "text = response.text.strip()\n",
    "lines = text.split(\"\\n\")\n",
    "\n",
    "# Quote each line\n",
    "quoted_lines = [f'\"{line}\"' for line in lines]\n",
    "\n",
    "# Count the occurrences of each quoted phrase\n",
    "phrase_counts = Counter(quoted_lines)\n",
    "\n",
    "# Print all the phrases sorted by their counts\n",
    "print(\"All the phrases in the file sorted by their counts are:\")\n",
    "for phrase, count in phrase_counts.most_common():\n",
    "    print(f\"{phrase}: {count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
